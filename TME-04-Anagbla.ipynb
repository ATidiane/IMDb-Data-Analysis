{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (3i026) -- 2018-2019\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Manon Ansart, Vincent Guigue, Marie-Jeanne Lesot, Christophe Marsala, Olivier Schwander.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME03: Programmation du kernel perceptron\n",
    "\n",
    "Le but de ce TP est de terminer l'extension de l'algoritheme du perceptron à l'aide de noyaux, avant de commencer à étudier les données du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double-cliquer ici et insérer les noms et prénoms de votre binôme*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-04</tt> et rajouter à la suite de <tt>tme-04</tt> les noms des membres du binômes séparés par un tiret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-04-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">** à la fin de la séance**</font>. C'est ce compte-rendu qui donne la note de base de la séance.\n",
    "- vous pouvez éventuellement compléter votre compte-rendu  pour obtenir des points bonus, dans ce cas, vous devez soumettre votre complément avant le début de la semaine suivante.\n",
    "\n",
    "** Sur la page Moodle de remise du travail <font color=\"RED\">ne pas oublier d'envoyer le compte rendu</font>** à la fin de la séance, la soumission de la version complémentaire post-séance se fera sur une page différente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise à jour de votre librairie IADS\n",
    "\n",
    "Comme lors de la séance précédente, vous devez utiliser les fonctions de la librairie IADS.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Ouvrir et compléter les fichiers Classifiers.py et utils.py**\n",
    "\n",
    "Rajouter dans la librairie les fonctions et classes et que vous avez écrites lors de la séance précédente. \n",
    "\n",
    "**Rappel**: dans un premier temps, vous devez écrire les classes et fonctions demandées dans le notebook de la séance de TDTME en cours. La séance suivante, vous rajouterez tout cela, une fois que vous l'aurez bien testé, dans vos fichiers de la librairie IADS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import random\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de LabeledSet\n",
    "from iads import LabeledSet as ls\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Trick\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons projeter (manuellement) les données 2D dans un espace de plus grande dimension. Voici un exemple de projection qui transforme un vecteur $(x_1,x_2)$ en un vecteur $(x_1,x_2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'the_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-41b0c3297a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKernelBias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'the_set' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class KernelBias:\n",
    "    def transform(self,x):\n",
    "        y = np.asarray([x[0],x[1],1])\n",
    "        return y\n",
    "\n",
    "k=KernelBias()\n",
    "k.transform(the_set.getX(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter la classe ClassifierPerceptronKernel qui prend un Kernel en paramètre, et calcule le perceptron sur la version \"kernélisée\" des données. Tester ce perceptron sur le dataset 1 (2 gaussiennes) et le dataset XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "class ClassifierPerceptronKernel(cl.Classifier):\n",
    "    def __init__(self,dimension_kernel,learning_rate,kernel):\n",
    "        \"\"\" Argument:\n",
    "                - intput_dimension (int) : dimension d'entrée des exemples\n",
    "                - learning_rate :\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        ##TODO\n",
    "        self.dimension_kernel = dimension_kernel\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kernel = kernel\n",
    "        self.w = np.random.rand(self.dimension_kernel)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        \"\"\" rend la prediction sur x (-1 ou +1)\n",
    "        \"\"\"\n",
    "        return np.sign(np.dot(self.kernel.transform(x), self.w))\n",
    "\n",
    "    \n",
    "    def train(self,labeledSet):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "        \"\"\"\n",
    "        ##TODO\n",
    "        f = self.predict(labeledSet.getX(indice))\n",
    "        for i in range(N):\n",
    "            indice = random.randint(0,labeledSet.size())\n",
    "            \n",
    "            if(labeledSet.getY(indice) * f < 0):\n",
    "                self.w+= self.learning_rate*2*labeledSet.getX(indice)*(labeledSet.getY(indice) - f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter le kernel : $(x_1,x_2) \\rightarrow (1,x_1,x_2,x_1*x_1,x_2*x_2,x_1*x_2)$. Entrainer le perceptron correspondant sur le XOR. Que constatez-vous ? Donnez une explication (explication donnée en cours lors de la prochaine séance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'indice' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fbf8fb91fb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m##TESTER SUR XOR ET DESSINER LA FRONTIèRE DE DECISION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mperceptron_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteste_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptron_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_frontiere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperceptron_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot2DSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fbf8fb91fb93>\u001b[0m in \u001b[0;36mteste_perceptron\u001b[0;34m(perceptron, labeledSet, N)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mteste_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeledSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy à l'itération {0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a01fec61e6c1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, labeledSet)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m##TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mindice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'indice' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "def teste_perceptron(perceptron, labeledSet, N):\n",
    "    for i in range(N):\n",
    "        perceptron.train(labeledSet)\n",
    "        print(\"Accuracy à l'itération {0}: {1}\".format(i, perceptron.accuracy(labeledSet)))\n",
    "\n",
    "    return perceptron\n",
    "\n",
    "def createXOR(nb_points,var):\n",
    "    ##TODO\n",
    "    half = nb_points // 2\n",
    "    var = np.array([[var, 0],[0, var]])\n",
    "    the_set = ut.createGaussianDataset(np.array([1,0]),var,np.array([0,0]),var,half)\n",
    "    second_set = ut.createGaussianDataset(np.array([0,1]),var,np.array([1,1]),var,half)\n",
    "    \n",
    "    for x, y in zip(second_set.x, second_set.y):\n",
    "        the_set.addExample(x, y)\n",
    "        \n",
    "    return the_set\n",
    "\n",
    "xor=createXOR(100,0.02)\n",
    "class KernelPoly:\n",
    "    def transform(self,x):\n",
    "        return np.array([1, x[0], x[1], x[0]**2, x[1]**2, x[0]* x[1]])\n",
    "\n",
    "N=100\n",
    "k=KernelPoly()\n",
    "perceptron_k=ClassifierPerceptronKernel(6,0.001,k)\n",
    "\n",
    "##TESTER SUR XOR ET DESSINER LA FRONTIèRE DE DECISION\n",
    "perceptron_k=teste_perceptron(perceptron_k, xor, N)\n",
    "ut.plot_frontiere(xor, perceptron_k)\n",
    "ut.plot2DSet(xor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoindreCarre(cl.Classifier):\n",
    "    \"\"\"un classifieur qui classifie sur des sur toute les donner\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dimension,learning_rate,kernel):\n",
    "        self.input_dimension = input_dimension\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kernel = kernel\n",
    "        self.w = np.random.rand(self.input_dimension)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return np.sign(np.dot(self.kernel.transform(x),self.kernel.transform(self.w)))\n",
    "    \n",
    "    \n",
    "    def train(self,labeledSet):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(N):\n",
    "            indice = random.randint(0,labeledSet.size()-1)\n",
    "            f = self.predict(labeledSet.getX(indice))\n",
    "            if((labeledSet.getY(indice) * f) < 0):\n",
    "                self.w += self.learning_rate * 2 * labeledSet.getX(indice)*(labeledSet.getY(indice) - f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'the_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c258df8fec1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelBias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmoindre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoindreCarre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mperceptron_moindre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteste_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoindre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_frontiere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoindre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot2DSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'the_set' is not defined"
     ]
    }
   ],
   "source": [
    "k = KernelBias()\n",
    "moindre = MoindreCarre(2,0.01, k)\n",
    "perceptron_moindre = teste_perceptron(moindre, the_set, N)\n",
    "ut.plot_frontiere(the_set, moindre)\n",
    "ut.plot2DSet(the_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en oeuvre sur des données réelles \n",
    "-------\n",
    "A partir de datasets trouvés sur le web, réaliser un ensemble d'expérimentations permettant de comparer les 3 classifiers (knn, perceptron de Rosenblatt et version kernélisée) que vous avez implémentés.\n",
    "\n",
    "Par exemple, vous pouvez utiliser les datasets suivants:\n",
    "- https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra\n",
    "- https://www.kaggle.com/uciml/indian-liver-patient-records\n",
    "- voir sur les données ouvertes de Paris : https://opendata.paris.fr/explore/?sort=modified\n",
    "\n",
    "Afin d'utiliser de tels jeux de données, il sera certainement nécessaire que vous réalisiez un prétraitement afin de pouvoir utiliser vos implémentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du projet\n",
    "\n",
    "Le projet est à rendre lors de la dernière séance de TD-TME de votre groupe qui aura lieu la semaine du **16 avril**. Lors de cette dernière séance, une soutenance sera organisée afin que vous présentiez le travail réalisé et les résultats obtenus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les données à utiliser sont des données issues d'une base de films et de notations faites par des spectateurs:\n",
    "- base MovieLens : https://grouplens.org/datasets/movielens/\n",
    "- base complémentaire `Movie Industrie`: https://www.kaggle.com/danielgrijalvas/movies\n",
    "\n",
    "\n",
    "<font color=\"RED\">**ATTENTION**: la base est très volumineuse (plus d'1Go) et ne pourra pas tenir sur votre répertoire de travail des machines de TME.</font>\n",
    "\n",
    "Dans un premier temps, vous travaillerez sur la version réduite de cette base (`ml-latest-small.zip` sur le site movilens) que vous pouvez récupérer sur les machines de TD-TME: `/users/Enseignants/marsala/3i026-2019/MovieLens-small.tgz`\n",
    "Cette version contient qu'une partie des lignes de la base originale.\n",
    "\n",
    "\n",
    "\n",
    "En salle de TD-TME, vous accéderez aux données dans les fichiers suivants (à ne pas recopier !):\n",
    "- répertoire : `/users/Enseignants/marsala/3i026-2019`\n",
    "- répertoire des données MovieLens version réduite : `/users/Enseignants/marsala/3i026-2019/MovieLens-small/` \n",
    "- fichier archive avec les données MovieLesns version réduite : `/users/Enseignants/marsala/3i026-2019/MovieLens-small.tgz`\n",
    "- répertoire des données MovieLens : `/users/Enseignants/marsala/3i026-2019/MovieLens/` \n",
    "  Il contient les fichiers CSV que vous pouvez ouvrir directement dans le notebook.\n",
    "- fichier `/users/Enseignants/marsala/3i026-2019/kaggle-movies.csv` : infos sur les films de la base Movie Industrie\n",
    "   \n",
    "   \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Réaliser des expérimentations avec la base MovieLens version réduite.\n",
    "\n",
    "Charger les données dans un dataframe, afficher des informations statistiques sur les données, commencer à réfléchir comment appliquer les classifieurs vus dans les séances précédentes sur ces données..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
